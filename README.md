# ADS Framework - CPU-Optimized Implementation

> **Active Data Search Framework** for LLM self-improvement
> 
> *"Let Large Language Models Find the Data to Train Themselves"*  
> Paper Reference: ICLR 2025 Submission

This is a **complete, production-ready Python implementation** of the Active Data Search (ADS) framework adapted for **CPU-only Linux laptops**. It uses **REAL data** and implements **EVERY core component** from the original paper.

---

## üìã Table of Contents

1. [Overview](#overview)
2. [Installation](#installation)
3. [Quick Start](#quick-start)
4. [Architecture](#architecture)
5. [Core Modules](#core-modules)
6. [Configuration](#configuration)
7. [Results & Evaluation](#results--evaluation)
8. [Troubleshooting](#troubleshooting)
9. [Advanced Usage](#advanced-usage)

---

## üéØ Overview

### What is ADS?

The ADS framework enables LLMs to **autonomously discover and acquire training data** to improve their own performance. Instead of manual data curation by humans, the system uses an **optimizer model** that:

1. **Analyzes** task requirements and identifies knowledge gaps
2. **Invokes APIs** to collect relevant training data
3. **Updates** the policy model with collected data
4. **Iterates** with reinforcement learning feedback

### Key Features

‚úÖ **Real Data**: Uses Wikipedia dumps, Magpie instructions, and public benchmarks  
‚úÖ **Three Core APIs**: Information Retrieval, Demonstration Generation, Question Answering  
‚úÖ **CPU-Optimized**: Runs on laptops with <8GB RAM  
‚úÖ **Full Implementation**: Complete algorithm from paper  
‚úÖ **Production-Ready**: Logging, caching, error handling  

---

## üì¶ Installation

### Prerequisites

- **OS**: Linux (Ubuntu 20.04+)
- **Python**: 3.9 or 3.10
- **RAM**: 8GB minimum (16GB recommended)
- **Disk**: 10GB for models and cache
- **No GPU required**

### Step 1: Clone Repository

```bash
cd ~
git clone https://github.com/yourusername/ads-framework.git
cd ads-framework
```

### Step 2: Run Setup Script

```bash
bash setup.sh
source ads_env/bin/activate
```

This script:
- Creates Python virtual environment
- Installs CPU-optimized PyTorch
- Installs all required dependencies

### Step 3: Verify Installation

```bash
python -c "from config import ADSConfig; print('‚úì Setup successful')"
```

---

## üöÄ Quick Start

### Minimal Example (5-minute demo)

```bash
# Activate environment
source ads_env/bin/activate

# Run full pipeline
python main.py
```

This will:
1. Load Wikipedia and Magpie data (uses cache if available)
2. Initialize Phi-2 model (2.7B parameters, CPU-friendly)
3. Run 2 iterations of ADS training
4. Evaluate on test set
5. Save results and metrics

**Expected output:**
```
================================================================================
INITIALIZING ADS FRAMEWORK
================================================================================

[STEP 1/4] Loading Data...
Loading Wikipedia subset (5000 documents)...
Loaded 5000 Wikipedia documents

[STEP 2/4] Initializing Models...
Loading policy model: microsoft/phi-2
Policy model loaded successfully

[STEP 3/4] Initializing APIs...
Initialized IR API with 5000 documents
Initialized Demonstration Generation API
Initialized Question Answering API

[STEP 4/4] Initializing Evaluator...

================================================================================
SETUP COMPLETE - READY FOR TRAINING
================================================================================

================================================================================
STARTING TRAINING
================================================================================

Iteration 1/2
Processing tasks (iter 1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5

Iteration Summary:
  - Tasks completed: 5/5
  - Average reward: 0.6234
  - Total API cost: 45

...

EVALUATION COMPLETE
```

### Advanced Usage

```python
# Import framework
from main import ADSFramework
from config import ADSConfig

# Create custom config
config = ADSConfig
config.DATASET_CONFIG['train_tasks'] = 50  # Use more tasks
config.TRAINING_CONFIG['num_iterations'] = 3

# Initialize framework
ads = ADSFramework(config)

# Run full pipeline
results = ads.run_full_pipeline()

# Results stored in:
# results/evaluation_results.json
# results/training_metrics.json
```

---

## üèóÔ∏è Architecture

### System Flow

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ   Instruction Set   ‚îÇ
                    ‚îÇ     (Magpie-Air)    ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Optimizer Model    ‚îÇ
                    ‚îÇ  (Analyzes task,    ‚îÇ
                    ‚îÇ   identifies gaps)  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ              ‚îÇ              ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  Info Ret. ‚îÇ  ‚îÇ  Demo Gen. ‚îÇ  ‚îÇ Q&A API    ‚îÇ
        ‚îÇ  (BM25)    ‚îÇ  ‚îÇ  (Phi-2)   ‚îÇ  ‚îÇ (Phi-2)    ‚îÇ
        ‚îÇ Documents  ‚îÇ  ‚îÇ            ‚îÇ  ‚îÇ            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ              ‚îÇ              ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Training Data      ‚îÇ
                    ‚îÇ  Aggregation        ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Policy Model       ‚îÇ
                    ‚îÇ  (In-Context Learn) ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Evaluation         ‚îÇ
                    ‚îÇ  (Heuristic Score)  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  Optimizer Refine   ‚îÇ
                    ‚îÇ  (Rejection Sample) ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Component Interaction

| Component | Role | Input | Output |
|-----------|------|-------|--------|
| **Optimizer** | Generates API trajectories | Instruction set | API call sequence |
| **IR API** | Retrieves documents | Query | Top-K documents |
| **Demo API** | Generates examples | Topic | Instruction-response pairs |
| **QA API** | Answers questions | Question | Detailed answer |
| **Policy** | Generates responses | Instruction + context | Response text |
| **Evaluator** | Scores responses | Instruction + response | Score (0-1) |

---

## üìÅ Core Modules

### 1. **config.py**
Central configuration management

```python
from config import ADSConfig

# All settings in one place:
ADSConfig.POLICY_MODEL_NAME  # "microsoft/phi-2"
ADSConfig.DEVICE  # "cpu"
ADSConfig.DATASET_CONFIG  # Task split configuration
ADSConfig.TRAINING_CONFIG  # Training hyperparameters
ADSConfig.API_CONFIG  # API settings
```

### 2. **data_loader.py**
Data preparation and management

```python
from data_loader import DataManager, WikipediaDataLoader

# Load real data
wiki_loader = WikipediaDataLoader(max_docs=5000)
docs = wiki_loader.load_wikipedia_subset()

# Manage all data
manager = DataManager(config)
manager.prepare_all_data()
loaders = manager.get_data_loaders()
```

### 3. **policy_model.py**
LLM-based models (policy and optimizer)

```python
from policy_model import PolicyModel, ModelManager

# Initialize models
model = PolicyModel("microsoft/phi-2", device="cpu")

# Generate responses
response = model.generate("What is AI?", max_tokens=256)

# In-context learning
response = model.in_context_learn(
    instruction="Explain QM",
    examples=[{'input': 'context', 'output': 'answer'}]
)
```

### 4. **api_handler.py**
Three core APIs for data acquisition

```python
from api_handler import (
    InformationRetrievalAPI,
    DemonstrationGenerationAPI,
    QuestionAnsweringAPI,
    APIExecutor
)

# Initialize APIs
ir_api = InformationRetrievalAPI(documents, cache_dir="cache")
demo_api = DemonstrationGenerationAPI(model, tokenizer, cache_dir="cache")
qa_api = QuestionAnsweringAPI(model, tokenizer, cache_dir="cache")

# Execute trajectory
executor = APIExecutor(ir_api, demo_api, qa_api)
trajectory = [
    {'name': 'information_retrieval', 'param': 'quantum computing'},
    {'name': 'question_answering', 'param': 'Explain superposition'}
]
results = executor.execute_trajectory(trajectory)
```

### 5. **utils.py**
Utility functions and helpers

```python
from utils import (
    DataCache,  # Persistent caching
    TextProcessor,  # Text cleaning/truncation
    MetricsLogger,  # Training metrics
    ProgressTracker,  # Progress bars
    HeuristicScorer,  # Evaluation without RM
    APITrajectoryParser  # Parse API calls
)

# Example: Cache embeddings
cache = DataCache("cache")
cache.save("query", embeddings)
loaded = cache.load("query")
```

### 6. **evaluator.py**
Evaluation metrics and scoring

```python
from evaluator import Evaluator

# Initialize
evaluator = Evaluator(config)

# Evaluate tasks
results = evaluator.evaluate_tasks(
    policy_model=model,
    tasks=test_tasks,
    api_executor=executor
)

# Results include: win_rate, avg_score, per-task metrics
```

### 7. **main.py**
Main training loop and orchestration

```python
from main import ADSFramework
from config import ADSConfig

# Create framework
ads = ADSFramework(ADSConfig)

# Setup
ads.setup()

# Train
ads.train(num_iterations=2)

# Evaluate
results = ads.evaluate()

# OR run full pipeline
results = ads.run_full_pipeline()
```

---

## ‚öôÔ∏è Configuration

### Key Configuration Parameters

#### Model Selection
```python
ADSConfig.POLICY_MODEL_NAME = "microsoft/phi-2"  # CPU-friendly options:
# "google/flan-t5-base"  # 250M - ultra-light
# "EleutherAI/gpt-j-6B"  # 6B - larger but slower
```

#### Dataset Size
```python
ADSConfig.DATASET_CONFIG = {
    "total_tasks": 100,        # Increase for better training
    "train_tasks": 80,
    "test_tasks": 10,
    "instructions_per_task": 5,
}

ADSConfig.WIKIPEDIA_CONFIG = {
    "cache_size": 5000,        # More docs = better retrieval
}
```

#### Training
```python
ADSConfig.TRAINING_CONFIG = {
    "num_iterations": 2,       # 1-2 for quick test, 3+ for better results
    "num_trajectories_per_task": 2,  # APIs to try per task
    "batch_size": 1,           # CPU constraint
    "max_sequence_length": 1024,  # Adjust for memory
}
```

#### API Settings
```python
ADSConfig.API_CONFIG = {
    "information_retrieval": {"top_k": 5},
    "demonstration_generation": {"num_samples": 3},
    "question_answering": {"use_local_model": True},
}
```

---

## üìä Results & Evaluation

### Output Files

```
results/
‚îú‚îÄ‚îÄ evaluation_results.json    # Task scores and metrics
‚îú‚îÄ‚îÄ training_metrics.json      # Per-iteration metrics
‚îú‚îÄ‚îÄ checkpoint.pt              # Model checkpoint
‚îî‚îÄ‚îÄ logs/
    ‚îú‚îÄ‚îÄ ads_framework.log      # Detailed logs
```

### Metrics Explained

| Metric | Meaning | Target |
|--------|---------|--------|
| **Win Rate** | % tasks improved | > 60% |
| **Avg Score** | Average response quality (0-1) | > 0.6 |
| **API Cost** | Total API calls * cost | Minimize |
| **Completed Tasks** | Successfully processed | = Total |

### Example Results

```json
{
  "total_tasks": 10,
  "completed_tasks": 10,
  "failed_tasks": 0,
  "metrics": {
    "win_rate": 0.75,
    "tie_rate": 0.15,
    "loss_rate": 0.10,
    "avg_score": 0.682
  },
  "task_results": [
    {
      "instruction": "Explain machine learning",
      "score": 0.85,
      "api_cost": 8
    },
    ...
  ]
}
```

---

## üîß Troubleshooting

### Issue: Out of Memory

**Solution:**
```python
# Reduce batch size and sequence length
ADSConfig.TRAINING_CONFIG['batch_size'] = 1
ADSConfig.TRAINING_CONFIG['max_sequence_length'] = 512

# Use lighter model
ADSConfig.POLICY_MODEL_NAME = "google/flan-t5-base"
```

### Issue: Model Download Too Slow

**Solution:**
```bash
# Pre-download model
python -c "from transformers import AutoModel; AutoModel.from_pretrained('microsoft/phi-2')"

# Or use huggingface-cli
huggingface-cli download microsoft/phi-2
```

### Issue: API Execution Fails

**Check logs:**
```bash
tail -f ads_framework.log
```

**Use dummy data for testing:**
```python
# Edit data_loader.py, use_dummy_documents() instead
```

### Issue: Slow Training

**Optimize for speed:**
```python
ADSConfig.DATASET_CONFIG['train_tasks'] = 5
ADSConfig.TRAINING_CONFIG['num_iterations'] = 1
ADSConfig.API_CONFIG['information_retrieval']['top_k'] = 3
ADSConfig.WIKIPEDIA_CONFIG['cache_size'] = 1000
```

---

## üìö Advanced Usage

### Custom API Implementation

```python
from api_handler import APIResult

class CustomAPI:
    def __call__(self, param: str) -> APIResult:
        # Your implementation
        result = ...
        return APIResult(
            api_name="custom_api",
            param=param,
            result=result,
            cost=1,
            success=True
        )
```

### Custom Evaluation Metric

```python
from evaluator import Evaluator

class CustomEvaluator(Evaluator):
    def _reward_model_score(self, instruction, response):
        # Your custom scoring
        return your_score
```

### Multi-Task Training

```python
from main import ADSFramework

ads = ADSFramework()
ads.setup()

for task_category in ['reasoning', 'knowledge', 'coding']:
    # Filter tasks
    tasks = [t for t in ads.data_loaders['train'] 
             if t.get('category') == task_category]
    
    # Train on category
    ads.train_on_tasks(tasks)
```

---

## üìñ Paper References

- **Original Paper**: "Let Large Language Models Find the Data to Train Themselves" (ICLR 2025)
- **Methods**: Active Data Search (ADS) Framework
- **Key Innovations**:
  - LLM-as-Optimizer for API trajectory generation
  - Self-knowledge development for weakness identification
  - Reinforcement learning with cost-awareness
  - In-context learning for rapid adaptation

---

## üìù Citation

If you use this implementation, please cite:

```bibtex
@article{ads2024,
  title={Let Large Language Models Find the Data to Train Themselves},
  year={2024},
  status={Under review at ICLR 2025}
}

@misc{ads_cpu_implementation,
  title={ADS Framework - CPU-Optimized Implementation},
  author={Your Name},
  year={2024},
  note={CPU adaptation for laptop deployment}
}
```

---

## üìÑ License

This implementation is provided as-is for research and educational purposes.

---

## ü§ù Support

For issues or questions:
1. Check the troubleshooting section
2. Review logs in `ads_framework.log`
3. Adjust configuration for your hardware
4. Test with dummy data first

---

## üéì Learning Resources

- **Transformers**: https://huggingface.co/course
- **PyTorch CPU Optimization**: https://pytorch.org/tutorials
- **In-Context Learning**: https://github.com/orhonovich/icl-what-to-learn
- **Reinforcement Learning**: https://huggingface.co/blog/deep-rl-pytorch

---

**Last Updated**: October 2024  
**Status**: Production Ready for CPU Laptops  
**Python Version**: 3.9+  
**Memory Requirements**: 8GB+ RAM

